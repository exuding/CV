{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 设置最长的字符长度为5个\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl)  + (4 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n"
     ]
    }
   ],
   "source": [
    "train_path = glob.glob('./data/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('./data/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "train_path = glob.glob('./data/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('./data/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=50, \n",
    "    shuffle=True, \n",
    "    num_workers=6,\n",
    ")\n",
    "\n",
    "val_path = glob.glob('./data/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('./data/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=50, \n",
    "    shuffle=False, \n",
    "    num_workers=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "\n",
    "        model_conv = models.resnet18(pretrained=True)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 11)\n",
    "        self.fc2 = nn.Linear(512, 11)\n",
    "        self.fc3 = nn.Linear(512, 11)\n",
    "        self.fc4 = nn.Linear(512, 11)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        return c1, c2, c3, c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        c0, c1, c2, c3 = model(input)\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "               criterion(c1, target[:, 1]) + \\\n",
    "               criterion(c2, target[:, 2]) + \\\n",
    "               criterion(c3, target[:, 3])\n",
    "\n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            c0, c1, c2, c3 = model(input)\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                   criterion(c1, target[:, 1]) + \\\n",
    "                   criterion(c2, target[:, 2]) + \\\n",
    "                   criterion(c3, target[:, 3])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "\n",
    "                c0, c1, c2, c3 = model(input)\n",
    "                output = np.concatenate([\n",
    "                    c0.data.numpy(),\n",
    "                    c1.data.numpy(),\n",
    "                    c2.data.numpy(),\n",
    "                    c3.data.numpy()], axis=1)\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.882579803466797\n",
      "4.428600311279297\n",
      "3.254946231842041\n",
      "2.9633963108062744\n",
      "2.596874713897705\n",
      "2.302093982696533\n",
      "Epoch: 0, Train loss: 3.462698571284612 \t Val loss: 3.469889237880707\n",
      "0.3517\n",
      "2.1719682216644287\n",
      "2.1778247356414795\n",
      "2.087566614151001\n",
      "2.1808290481567383\n",
      "2.231290340423584\n",
      "2.358868360519409\n",
      "Epoch: 1, Train loss: 2.1361371006568275 \t Val loss: 2.9541943854093553\n",
      "0.4291\n",
      "1.727794885635376\n",
      "1.866249918937683\n",
      "1.291660189628601\n",
      "2.354145050048828\n",
      "1.4648103713989258\n",
      "1.5552642345428467\n",
      "Epoch: 2, Train loss: 1.7850018884738286 \t Val loss: 2.7120111042261126\n",
      "0.479\n",
      "1.1808650493621826\n",
      "1.043211579322815\n",
      "1.7390122413635254\n",
      "1.2948334217071533\n",
      "0.9847943186759949\n",
      "1.035228967666626\n",
      "Epoch: 3, Train loss: 1.57057877967755 \t Val loss: 2.6458248472213746\n",
      "0.5133\n",
      "1.4377286434173584\n",
      "1.5799466371536255\n",
      "1.2805849313735962\n",
      "2.1839420795440674\n",
      "1.0213991403579712\n",
      "1.3405755758285522\n",
      "Epoch: 4, Train loss: 1.442296913464864 \t Val loss: 2.7792397141456604\n",
      "0.504\n",
      "1.1095222234725952\n",
      "1.536912441253662\n",
      "0.451479971408844\n",
      "1.1045465469360352\n",
      "0.9502590298652649\n",
      "1.405961513519287\n",
      "Epoch: 5, Train loss: 1.3099042976399262 \t Val loss: 2.7621271634101867\n",
      "0.4907\n",
      "1.567765712738037\n",
      "1.6143704652786255\n",
      "1.3082846403121948\n",
      "1.2370471954345703\n",
      "1.762574553489685\n",
      "1.8147162199020386\n",
      "Epoch: 6, Train loss: 1.2348593115806579 \t Val loss: 2.614851541519165\n",
      "0.5191\n",
      "1.380675196647644\n",
      "0.9680433869361877\n",
      "1.0593336820602417\n",
      "1.2201130390167236\n",
      "0.8782862424850464\n",
      "1.4938303232192993\n",
      "Epoch: 7, Train loss: 1.1478979200124741 \t Val loss: 2.5377661073207856\n",
      "0.5326\n",
      "1.1577781438827515\n",
      "0.8246301412582397\n",
      "1.370630145072937\n",
      "1.7348182201385498\n",
      "1.1404590606689453\n",
      "1.0811082124710083\n",
      "Epoch: 8, Train loss: 1.053317710707585 \t Val loss: 2.529494144320488\n",
      "0.5426\n",
      "1.2433620691299438\n",
      "1.071946144104004\n",
      "1.6596994400024414\n",
      "1.1801971197128296\n",
      "1.169277310371399\n",
      "0.8701409101486206\n",
      "Epoch: 9, Train loss: 0.9960666074355443 \t Val loss: 2.4912331640720367\n",
      "0.5431\n",
      "1.34947669506073\n",
      "0.5686457753181458\n",
      "0.9833832383155823\n",
      "0.6304922103881836\n",
      "1.1514421701431274\n",
      "0.8388577103614807\n",
      "Epoch: 10, Train loss: 0.9230521541833877 \t Val loss: 2.422700780034065\n",
      "0.5604\n",
      "0.8048272728919983\n",
      "0.9017820358276367\n",
      "0.6271004676818848\n",
      "0.7034978866577148\n",
      "0.7414553165435791\n",
      "0.736931324005127\n",
      "Epoch: 11, Train loss: 0.8678622656563918 \t Val loss: 2.495464890599251\n",
      "0.5572\n",
      "0.6147316098213196\n",
      "1.0447666645050049\n",
      "0.5808897614479065\n",
      "1.0175673961639404\n",
      "0.843801736831665\n",
      "0.8895049095153809\n",
      "Epoch: 12, Train loss: 0.8125982563694318 \t Val loss: 2.556708487868309\n",
      "0.5612\n",
      "0.49122968316078186\n",
      "1.0365198850631714\n",
      "0.9572367072105408\n",
      "0.8074669241905212\n",
      "0.7286661267280579\n",
      "0.9650018215179443\n",
      "Epoch: 13, Train loss: 0.7637093824148178 \t Val loss: 2.7715001356601716\n",
      "0.5429\n",
      "1.4471015930175781\n",
      "1.0090452432632446\n",
      "0.8567768335342407\n",
      "0.6303179860115051\n",
      "0.8746995329856873\n",
      "0.7599741220474243\n",
      "Epoch: 14, Train loss: 0.718782703752319 \t Val loss: 2.6094539618492125\n",
      "0.5634\n",
      "0.8442707061767578\n",
      "0.5105241537094116\n",
      "0.5007838606834412\n",
      "0.6834829449653625\n",
      "0.5529695749282837\n",
      "0.7468946576118469\n",
      "Epoch: 15, Train loss: 0.6557406418770552 \t Val loss: 2.6893309319019316\n",
      "0.5676\n",
      "0.38192057609558105\n",
      "0.24703280627727509\n",
      "0.5692248344421387\n",
      "0.7820141911506653\n",
      "0.38853323459625244\n",
      "0.6508997082710266\n",
      "Epoch: 16, Train loss: 0.600136410916845 \t Val loss: 2.85882011115551\n",
      "0.5547\n",
      "0.5841658711433411\n",
      "0.5924866795539856\n",
      "0.1894630789756775\n",
      "0.4651426374912262\n",
      "0.9289031624794006\n",
      "0.6181720495223999\n",
      "Epoch: 17, Train loss: 0.5671486857533455 \t Val loss: 2.857024866938591\n",
      "0.5597\n",
      "0.5398183465003967\n",
      "0.40456777811050415\n",
      "0.6166179180145264\n",
      "0.721062421798706\n",
      "0.452711284160614\n",
      "0.46059903502464294\n",
      "Epoch: 18, Train loss: 0.5130133316727976 \t Val loss: 3.065804955363274\n",
      "0.5424\n",
      "0.07181567698717117\n",
      "0.1439669281244278\n",
      "0.2537786066532135\n",
      "0.3909681439399719\n",
      "0.47811928391456604\n",
      "0.36944636702537537\n",
      "Epoch: 19, Train loss: 0.4823326070730885 \t Val loss: 3.1243783181905744\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "best_loss = 1000.0\n",
    "\n",
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    \n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader, model, 1)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "    \n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print(val_char_acc)\n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "test_path = glob.glob('./data/mchar_test_a/*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "    test_predict_label[:, :11].argmax(1),\n",
    "    test_predict_label[:, 11:22].argmax(1),\n",
    "    test_predict_label[:, 22:33].argmax(1),\n",
    "    test_predict_label[:, 33:44].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "    \n",
    "import pandas as pd\n",
    "df_submit = pd.read_csv('./data/mchar_sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('renset18_3.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
