{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, shutil, json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset(Dataset):\n",
    "    def __init__(self, img_path, img_label, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_label = img_label\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # 设置最长的字符长度为4个\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl) + (4 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:4]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gauss_blur():\n",
    "    def __init__(self, w, std):\n",
    "        self.w = w\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.randint(0, 1) == 0:\n",
    "            return img\n",
    "        else:\n",
    "            img = np.asarray(img, np.float)\n",
    "            img = cv2.GaussianBlur(img, (self.w, self.w), self.std)\n",
    "            img = Image.fromarray(np.uint8(img))\n",
    "            return img\n",
    "\n",
    "\n",
    "\n",
    "class Noise():\n",
    "    \"\"\"Adds gaussian noise to a tensor.\n",
    "\n",
    "    Example:\n",
    "        >>> transforms.Compose([\n",
    "        >>>     transforms.ToTensor(),\n",
    "        >>>     Noise(0.1, 0.05)),\n",
    "        >>> ])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, stddev):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        if random.randint(0, 1) == 0:\n",
    "            return tensor\n",
    "        else:\n",
    "            noise = torch.zeros_like(tensor).normal_(self.mean, self.stddev)\n",
    "            return tensor.add_(noise)\n",
    "\n",
    "model_urls = {'resnet50': './weights/resnet50.pth',}\n",
    "\n",
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "\n",
    "        model_conv = models.resnet50(pretrained=False)\n",
    "        pre = torch.load(model_urls['resnet50'])\n",
    "        model_conv.load_state_dict(pre)\n",
    "        model_conv.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        self.fc1 = nn.Linear(2048, 11)\n",
    "        self.fc1_2 = nn.Linear(1024, 11)\n",
    "        self.fc2 = nn.Linear(2048, 11)\n",
    "        self.fc2_2 = nn.Linear(1024, 11)\n",
    "        self.fc3 = nn.Linear(2048, 11)\n",
    "        self.fc3_2 = nn.Linear(1024, 11)\n",
    "        self.fc4 = nn.Linear(2048, 11)\n",
    "        self.fc4_2 = nn.Linear(1024, 11)\n",
    "\n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        # print(feat.shape)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        return c1, c2, c3, c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        c0, c1, c2, c3 = model(input)\n",
    "        loss = criterion(c0, target[:, 0]) + \\\n",
    "               criterion(c1, target[:, 1]) + \\\n",
    "               criterion(c2, target[:, 2]) + \\\n",
    "               criterion(c3, target[:, 3])\n",
    "\n",
    "        # loss /= 6\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.item())\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if use_cuda:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            c0, c1, c2, c3 = model(input)\n",
    "            loss = criterion(c0, target[:, 0]) + \\\n",
    "                   criterion(c1, target[:, 1]) + \\\n",
    "                   criterion(c2, target[:, 2]) + \\\n",
    "                   criterion(c3, target[:, 3])\n",
    "            # loss /= 6\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "\n",
    "def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                if use_cuda:\n",
    "                    input = input.cuda()\n",
    "\n",
    "                c0, c1, c2, c3 = model(input)\n",
    "                output = np.concatenate([\n",
    "                    c0.data.numpy(),\n",
    "                    c1.data.numpy(),\n",
    "                    c2.data.numpy(),\n",
    "                    c3.data.numpy()], axis=1)\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "10000 10000\n",
      "9.445777893066406\n",
      "6.630636215209961\n",
      "5.966912269592285\n",
      "5.635322570800781\n",
      "5.1511006355285645\n",
      "4.830178737640381\n",
      "4.758767127990723\n",
      "4.853681564331055\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  4  0 10]\n",
      " [ 1  6 10 10]\n",
      " ...\n",
      " [ 3  0 10 10]\n",
      " [ 4 10 10 10]\n",
      " [ 1  0 10 10]]\n",
      "Epoch: 0, Train loss: 5.34731067276001 \t Val loss: 4.4708329086303715\n",
      "0.1839\n",
      "4.760036945343018\n",
      "3.4418139457702637\n",
      "3.6271145343780518\n",
      "2.844505548477173\n",
      "3.2260055541992188\n",
      "2.964606761932373\n",
      "3.401989459991455\n",
      "2.4166505336761475\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 1  1 10 10]\n",
      " [ 1  0 10 10]\n",
      " ...\n",
      " [ 1  2 10 10]\n",
      " [ 1  2 10 10]\n",
      " [ 1  9 10 10]]\n",
      "Epoch: 1, Train loss: 3.167136542797089 \t Val loss: 3.7086707515716553\n",
      "0.3146\n",
      "2.126927375793457\n",
      "3.2195024490356445\n",
      "2.2368428707122803\n",
      "2.6995530128479004\n",
      "2.498530864715576\n",
      "2.334381103515625\n",
      "1.789259910583496\n",
      "2.1640260219573975\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  0 10 10]\n",
      " [ 6 10 10 10]\n",
      " ...\n",
      " [ 2 10 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 4  9 10 10]]\n",
      "Epoch: 2, Train loss: 2.4041893712679543 \t Val loss: 3.1225586795806883\n",
      "0.4264\n",
      "2.0772314071655273\n",
      "2.003114700317383\n",
      "1.6662453413009644\n",
      "1.5125370025634766\n",
      "1.862192988395691\n",
      "2.128657817840576\n",
      "2.5781939029693604\n",
      "2.370607852935791\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  0  0 10]\n",
      " [ 9  6 10 10]\n",
      " ...\n",
      " [ 2  2 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 1  5 10 10]]\n",
      "Epoch: 3, Train loss: 2.0680226499239605 \t Val loss: 2.8984536218643187\n",
      "0.4663\n",
      "1.8086868524551392\n",
      "2.851461172103882\n",
      "1.724045753479004\n",
      "1.5686016082763672\n",
      "2.1867456436157227\n",
      "2.2097301483154297\n",
      "1.4231295585632324\n",
      "1.8381320238113403\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  0  0 10]\n",
      " [ 6  6 10 10]\n",
      " ...\n",
      " [ 2  3 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 9  5 10 10]]\n",
      "Epoch: 4, Train loss: 1.8809861070315044 \t Val loss: 2.8101907653808595\n",
      "0.4985\n",
      "1.2573169469833374\n",
      "1.9056899547576904\n",
      "1.876296043395996\n",
      "1.4130146503448486\n",
      "1.8827158212661743\n",
      "1.0346423387527466\n",
      "2.1924984455108643\n",
      "1.088380217552185\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  0  2 10]\n",
      " [ 6  6 10 10]\n",
      " ...\n",
      " [ 9  1 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 1  5 10 10]]\n",
      "Epoch: 5, Train loss: 1.747681288321813 \t Val loss: 2.6863312616348267\n",
      "0.5119\n",
      "1.6579900979995728\n",
      "1.7411760091781616\n",
      "2.084825277328491\n",
      "1.8256151676177979\n",
      "1.8556097745895386\n",
      "1.2263216972351074\n",
      "2.065126657485962\n",
      "1.5733959674835205\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  1  0 10]\n",
      " [ 6  6 10 10]\n",
      " ...\n",
      " [ 2  3 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 3  5 10 10]]\n",
      "Epoch: 6, Train loss: 1.6724416785240173 \t Val loss: 2.6073779859542845\n",
      "0.5048\n",
      "2.3050105571746826\n",
      "1.8285777568817139\n",
      "1.774228572845459\n",
      "1.770249605178833\n",
      "1.6807137727737427\n",
      "3.07211971282959\n",
      "2.6198368072509766\n",
      "1.4003028869628906\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  1  0 10]\n",
      " [ 6  6 10 10]\n",
      " ...\n",
      " [ 2  3 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 1  5 10 10]]\n",
      "Epoch: 7, Train loss: 1.589389515399933 \t Val loss: 2.5401895909309387\n",
      "0.5309\n",
      "0.7981346249580383\n",
      "1.4525108337402344\n",
      "1.4836163520812988\n",
      "1.3032950162887573\n",
      "2.1490092277526855\n",
      "1.4042210578918457\n",
      "2.3017897605895996\n",
      "1.8135080337524414\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  1  0 10]\n",
      " [ 6 10 10 10]\n",
      " ...\n",
      " [ 2  1 10 10]\n",
      " [ 2 10 10 10]\n",
      " [ 1  4  3 10]]\n",
      "Epoch: 8, Train loss: 1.5332894347508748 \t Val loss: 2.534113700628281\n",
      "0.5445\n",
      "1.122604489326477\n",
      "1.4083985090255737\n",
      "1.784538984298706\n",
      "1.9794620275497437\n",
      "1.261393427848816\n",
      "1.4157187938690186\n",
      "1.7209811210632324\n",
      "1.3887039422988892\n",
      "暂时结束。。。。。\n",
      "val_predict_label [[ 5 10 10 10]\n",
      " [ 2  1  0 10]\n",
      " [ 6 10 10 10]\n",
      " ...\n",
      " [ 2  7 10 10]\n",
      " [ 2  2 10 10]\n",
      " [ 1  4  3 10]]\n",
      "Epoch: 9, Train loss: 1.4725194209416708 \t Val loss: 2.5023881621360777\n",
      "0.553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_path = glob.glob('./data/mchar_train/*.png')\n",
    "train_path.sort()\n",
    "train_json = json.load(open('./data/mchar_train.json'))\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((70, 140)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
    "                    #添加的\n",
    "                    transforms.RandomGrayscale(0.5),\n",
    "                    transforms.RandomRotation(15),\n",
    "                    transforms.ToTensor(),\n",
    "                    Noise(0, 0.05),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=40,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "val_path = glob.glob('./data/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('./data/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=40,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "\n",
    "model = SVHN_Model1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "best_loss = 1000.0\n",
    "\n",
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    train_loss = train(train_loader, model, criterion, optimizer)\n",
    "    val_loss = validate(val_loader, model, criterion)\n",
    "    print('暂时结束。。。。。')\n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict(val_loader, model, 1)\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "    ]).T\n",
    "    print('val_predict_label', val_predict_label)\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        val_label_pred.append(''.join(map(str, x[x != 10])))\n",
    "\n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "\n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print(val_char_acc)\n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_path = glob.glob('./data/mchar_test_a/*.png')\n",
    "test_path.sort()\n",
    "test_label = [[1]] * len(test_path)\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SVHNDataset(test_path, test_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])),\n",
    "    batch_size=40,\n",
    "    shuffle=False,\n",
    "    num_workers=5,\n",
    ")\n",
    "\n",
    "test_predict_label = predict(test_loader, model, 1)\n",
    "\n",
    "test_label = [''.join(map(str, x)) for x in test_loader.dataset.img_label]\n",
    "test_predict_label = np.vstack([\n",
    "        test_predict_label[:, :11].argmax(1),\n",
    "        test_predict_label[:, 11:22].argmax(1),\n",
    "        test_predict_label[:, 22:33].argmax(1),\n",
    "        test_predict_label[:, 33:44].argmax(1),\n",
    "]).T\n",
    "\n",
    "test_label_pred = []\n",
    "for x in test_predict_label:\n",
    "    test_label_pred.append(''.join(map(str, x[x != 10])))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_submit = pd.read_csv('./data/mchar_sample_submit_A.csv')\n",
    "df_submit['file_code'] = test_label_pred\n",
    "df_submit.to_csv('renset18_4.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
